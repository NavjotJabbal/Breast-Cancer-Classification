{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\navjo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, random, shutil\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Dataset Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATASET = \"datasets/original\"\n",
    "BASE_PATH = \"datasets/idc\"\n",
    "TRAIN_PATH = os.path.sep.join([BASE_PATH, \"training\"])\n",
    "VAL_PATH = os.path.sep.join([BASE_PATH, \"validation\"])\n",
    "TEST_PATH =  os.path.sep.join([BASE_PATH, \"testing\"])\n",
    "TRAIN_SPLIT = 0.8\n",
    "VAL_SPLIT =  0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Building training set\n",
      " Building validation set\n",
      " Building testing set\n"
     ]
    }
   ],
   "source": [
    "originalPaths = list(paths.list_images(INPUT_DATASET))\n",
    "random.seed (7)\n",
    "random.shuffle(originalPaths)\n",
    "index = int(len(originalPaths)*TRAIN_SPLIT)\n",
    "trainPaths = originalPaths[:index]\n",
    "testPaths = originalPaths[index:]\n",
    "index = int(len(trainPaths)*VAL_SPLIT)\n",
    "valPaths = trainPaths [:index]\n",
    "trainPaths = trainPaths[index:]\n",
    "datasets = [(\"training\", trainPaths, TRAIN_PATH),\n",
    "            (\"validation\" , valPaths, VAL_PATH),\n",
    "            (\"testing\", testPaths, TEST_PATH)] \n",
    "for (setType, originalPaths, basePath) in datasets :\n",
    "        print (f' Building {setType} set')\n",
    "        if not os.path.exists(basePath):\n",
    "            print(f' Building directory {basePath}' )\n",
    "            os.makedirs(basePath)\n",
    "        for path in originalPaths:\n",
    "            file = path.split(os.path.sep) [ -1]\n",
    "            label = file [-5:-4]\n",
    "            labelPath = os.path.sep.join([basePath,label])\n",
    "            if not os.path.exists(labelPath) :\n",
    "                print(f'BuiIding directory {labelPath}' )\n",
    "                os.makedirs(labelPath)\n",
    "            newPath = os.path.sep.join([labelPath, file])\n",
    "            shutil.copy2(path, newPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the CancerNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CancerNet:\n",
    "    def build(width, height, depth, classes):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        shape = (height, width, depth)\n",
    "        channelDim = -1\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            shape = (depth, height, width)\n",
    "            channelDim = 1\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu', input_shape = shape))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis = channelDim) )\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis = channelDim))\n",
    "        model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis = channelDim))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "        model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis = channelDim))\n",
    "        model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis = channelDim))\n",
    "        model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis = channelDim))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "        model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(units = 256, activation = 'relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(axis = channelDim))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units = classes, activation = 'softmax'))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation and ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 255815 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "matplotlib.use('Agg')\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255,\n",
    "                                shear_range = 0.2,\n",
    "                                zoom_range = 0.2,\n",
    "                                horizontal_flip = True)\n",
    "Training_set = train_datagen.flow_from_directory('datasets/idc/training',\n",
    "                                                 target_size = (64,64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7995"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Configuration and Augmentation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 255815 images belonging to 2 classes.\n",
      "Found 42660 images belonging to 2 classes.\n",
      "Found 99906 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS=10; INIT_LR=1e-2; BS=32\n",
    "\n",
    "trainPaths = list(paths.list_images(TRAIN_PATH))\n",
    "lenVal = len(list(paths.list_images(VAL_PATH)))\n",
    "lenTest = len(list(paths.list_images(TEST_PATH)))\n",
    "trainLabels = [int(p.split(os.path.sep)[-2]) for p in trainPaths]\n",
    "trainLabels = to_categorical(trainLabels)\n",
    "classTotals = trainLabels.sum(axis=0)\n",
    "classWeight = classTotals.max()/classTotals\n",
    "\n",
    "trainAug = ImageDataGenerator(\n",
    "    rescale = 1/255.0,\n",
    "    rotation_range = 20,\n",
    "    zoom_range = 0.05,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    shear_range = 0.05,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = \"nearest\")\n",
    "\n",
    "valAug = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (48,48),\n",
    "    color_mode = \"rgb\",\n",
    "    shuffle = True,\n",
    "    batch_size = BS)\n",
    "valGen = valAug.flow_from_directory(\n",
    "    VAL_PATH,\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (48,48),\n",
    "    color_mode = \"rgb\",\n",
    "    shuffle = False,\n",
    "    batch_size = BS)\n",
    "testGen = valAug.flow_from_directory(\n",
    "TEST_PATH,\n",
    "class_mode = \"categorical\",\n",
    "target_size = (48,48),\n",
    "color_mode = \"rgb\",\n",
    "shuffle = False,\n",
    "batch_size = BS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition, Compilation, and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7995/7995 [==============================] - 2838s 355ms/step - loss: 0.3865 - accuracy: 0.8365 - val_loss: 0.4306 - val_accuracy: 0.8193\n",
      "Epoch 2/10\n",
      "7995/7995 [==============================] - 1925s 241ms/step - loss: 0.3469 - accuracy: 0.8534 - val_loss: 0.3565 - val_accuracy: 0.8639\n",
      "Epoch 3/10\n",
      "7995/7995 [==============================] - 3564s 446ms/step - loss: 0.3323 - accuracy: 0.8601 - val_loss: 0.5467 - val_accuracy: 0.8104\n",
      "Epoch 4/10\n",
      "7995/7995 [==============================] - 3996s 500ms/step - loss: 0.3266 - accuracy: 0.8634 - val_loss: 0.3984 - val_accuracy: 0.8447\n",
      "Epoch 5/10\n",
      "7995/7995 [==============================] - 2513s 314ms/step - loss: 0.3196 - accuracy: 0.8669 - val_loss: 0.4175 - val_accuracy: 0.8510\n",
      "Epoch 6/10\n",
      "7995/7995 [==============================] - 5295s 662ms/step - loss: 0.3178 - accuracy: 0.8676 - val_loss: 0.5346 - val_accuracy: 0.8329\n",
      "Epoch 7/10\n",
      "7995/7995 [==============================] - 4708s 589ms/step - loss: 0.3138 - accuracy: 0.8694 - val_loss: 0.3983 - val_accuracy: 0.8359\n",
      "Epoch 8/10\n",
      "7995/7995 [==============================] - 2543s 318ms/step - loss: 0.3095 - accuracy: 0.8717 - val_loss: 0.3091 - val_accuracy: 0.8718\n",
      "Epoch 9/10\n",
      "7995/7995 [==============================] - 2493s 312ms/step - loss: 0.3078 - accuracy: 0.8723 - val_loss: 0.3153 - val_accuracy: 0.8710\n",
      "Epoch 10/10\n",
      "7995/7995 [==============================] - 3126s 391ms/step - loss: 0.3052 - accuracy: 0.8731 - val_loss: 0.4665 - val_accuracy: 0.8209\n"
     ]
    }
   ],
   "source": [
    "model = CancerNet.build(width = 48, height = 48, depth = 3, classes = 2)\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = 'adam', metrics = [\"accuracy\"])\n",
    "M = model.fit(x=trainGen, validation_data = valGen, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 46, 46, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 46, 46, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 23, 23, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 23, 23, 32)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 21, 21, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 19, 19, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 19, 19, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 9, 9, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 7, 7, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 5, 5, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 5, 5, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 3, 3, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 1, 1, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1, 1, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 186690 (729.26 KB)\n",
      "Trainable params: 185474 (724.51 KB)\n",
      "Non-trainable params: 1216 (4.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navjo\\AppData\\Local\\Temp\\ipykernel_18384\\4127909763.py:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred_indices = model.predict_generator(testGen, steps = (lenTest//BS)+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.80      0.87     71451\n",
      "           1       0.64      0.87      0.74     28455\n",
      "\n",
      "    accuracy                           0.82     99906\n",
      "   macro avg       0.79      0.84      0.80     99906\n",
      "weighted avg       0.85      0.82      0.83     99906\n",
      "\n",
      "[[57308 14143]\n",
      " [ 3674 24781]]\n",
      "Accuracy: 0.8216623626208636\n",
      "Specificity: 0.8708838516956598\n",
      "Sensitivity: 0.8020601531119228\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,N), M\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,N), M\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,N), \u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43macc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,N), M\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m], label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitie(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Loss and Accuracy on the IDC Dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "print(\"Now evaluating the model\")\n",
    "testGen.reset( )\n",
    "pred_indices = model.predict_generator(testGen, steps = (lenTest//BS)+1)\n",
    "pred_indices = np.argmax(pred_indices, axis = 1)\n",
    "print(classification_report(testGen.classes, pred_indices, target_names = testGen.class_indices.keys()))\n",
    "cm = confusion_matrix(testGen.classes, pred_indices)\n",
    "total = sum(sum(cm))\n",
    "accuracy = (cm[0,0]+cm[1,1])/total\n",
    "specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print(cm)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Specificity: {specificity}')\n",
    "print(f'Sensitivity: {sensitivity}')\n",
    "\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0,N), M.history[\"loss\"], label = \"train_loss\")\n",
    "plt.plot(np.arange(0,N), M.history[\"val_loss\"], label = \"val_loss\")\n",
    "plt.plot(np.arange(0,N), M.history[\"acc\"], label = \"train_acc\")\n",
    "plt.plot(np.arange(0,N), M.history[\"val_acc\"], label = \"val_acc\")\n",
    "plt.titie(\"Training Loss and Accuracy on the IDC Dataset\")\n",
    "plt.xlabel(\"Epoch No.\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc = \"lower left\")\n",
    "plt.savefig('plot.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
